<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Orb</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        html, body {
            width: 100%;
            height: 100%;
            background: transparent;
            overflow: hidden;
            /* Removed -webkit-app-region: drag - we handle dragging manually */
        }
        
        .orb-container {
            position: absolute;
            bottom: 20px;
            right: 20px;
            width: 80px;
            height: 80px;
        }
        
        .orb {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            /* Use OneReach orb graphic */
            background-image: url('assets/banner.png');
            background-size: cover;
            background-position: center;
            cursor: grab;
            display: flex;
            align-items: center;
            justify-content: center;
            -webkit-app-region: no-drag;
            position: relative;
            /* No glow by default - clean look */
            box-shadow: none;
            transition: transform 0.3s ease, filter 0.3s ease;
            animation: orb-float 6s ease-in-out infinite;
        }
        
        .orb:hover {
            transform: scale(1.1);
            filter: brightness(1.1);
        }
        
        .orb.listening {
            box-shadow: 0 0 8px rgba(234, 179, 8, 0.5);
            animation: orb-float 4s ease-in-out infinite, orb-breathe 1.5s ease-in-out infinite;
        }
        
        .orb.processing {
            box-shadow: 0 0 8px rgba(249, 115, 22, 0.5);
            animation: orb-float 3s ease-in-out infinite, orb-pulse 0.8s ease-in-out infinite;
        }
        
        .orb.error {
            box-shadow: 0 0 8px rgba(239, 68, 68, 0.5);
            animation: orb-shake 0.5s ease-in-out;
        }
        
        /* Gentle floating motion */
        @keyframes orb-float {
            0%, 100% { 
                transform: translate(0, 0); 
            }
            25% { 
                transform: translate(2px, -3px); 
            }
            50% { 
                transform: translate(-1px, -1px); 
            }
            75% { 
                transform: translate(-2px, -2px); 
            }
        }
        
        /* Breathing glow when listening */
        @keyframes orb-breathe {
            0%, 100% { 
                box-shadow: 0 0 6px rgba(234, 179, 8, 0.4);
                filter: brightness(1);
            }
            50% { 
                box-shadow: 0 0 12px rgba(234, 179, 8, 0.6);
                filter: brightness(1.1);
            }
        }
        
        /* Pulse when processing */
        @keyframes orb-pulse {
            0%, 100% { 
                transform: scale(1);
            }
            50% { 
                transform: scale(1.05);
            }
        }
        
        /* Shake on error */
        @keyframes orb-shake {
            0%, 100% { transform: translateX(0); }
            20% { transform: translateX(-4px); }
            40% { transform: translateX(4px); }
            60% { transform: translateX(-4px); }
            80% { transform: translateX(4px); }
        }
        
        /* Ring effects - hidden by default, only show when listening */
        .ring, .ring-secondary {
            display: none;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80px;
            height: 80px;
            border-radius: 50%;
            pointer-events: none;
        }
        
        .ring {
            border: 1px solid rgba(234, 179, 8, 0.4);
        }
        
        .orb.listening + .ring {
            display: block;
            animation: ring-expand 2s ease-out infinite;
        }
        
        @keyframes ring-expand {
            0% { 
                transform: translate(-50%, -50%) scale(1); 
                opacity: 0.5;
            }
            100% { 
                transform: translate(-50%, -50%) scale(1.6); 
                opacity: 0;
            }
        }
        
        /* Mic overlay icon (subtle, appears on hover or when idle) */
        .mic-overlay {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 24px;
            height: 24px;
            opacity: 0;
            transition: opacity 0.3s ease;
            pointer-events: none;
        }
        
        .mic-overlay svg {
            width: 100%;
            height: 100%;
            fill: rgba(255, 255, 255, 0.9);
            filter: drop-shadow(0 2px 4px rgba(0, 0, 0, 0.3));
        }
        
        .orb:hover .mic-overlay {
            opacity: 0.8;
        }
        
        .orb.listening .mic-overlay {
            opacity: 0;
        }
        
        /* Transcript tooltip - elegant floating text */
        .transcript-tooltip {
            position: absolute;
            background: linear-gradient(135deg, rgba(15, 15, 20, 0.95) 0%, rgba(25, 25, 35, 0.9) 100%);
            color: rgba(255, 255, 255, 0.95);
            padding: 14px 20px;
            border-radius: 16px;
            font-size: 14px;
            font-weight: 400;
            letter-spacing: 0.3px;
            line-height: 1.5;
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Text', 'Segoe UI', Roboto, sans-serif;
            max-width: 320px;
            text-align: center;
            white-space: normal;
            word-wrap: break-word;
            opacity: 0;
            pointer-events: none;
            -webkit-app-region: no-drag;
            /* Frosted glass effect */
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            /* Subtle border glow */
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 
                0 8px 32px rgba(0, 0, 0, 0.4),
                0 0 0 1px rgba(255, 255, 255, 0.05),
                inset 0 1px 0 rgba(255, 255, 255, 0.1);
            /* Position above orb, right-aligned with orb */
            bottom: 115px;
            right: 0;
            left: auto;
            /* Animation properties */
            transform: translateY(10px);
            /* Ensure text doesn't get clipped */
            overflow: visible;
            transition: opacity 0.4s ease, transform 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        }
        
        .transcript-tooltip.visible {
            opacity: 1;
            transform: translateY(0);
        }
        
        /* Fading out state */
        .transcript-tooltip.fading {
            opacity: 0;
            transform: translateY(-10px);
            transition: opacity 0.8s ease-out, transform 0.8s ease-out;
        }
        
        .transcript-tooltip.interim {
            color: rgba(180, 180, 200, 0.9);
            font-style: italic;
            font-weight: 300;
        }
        
        /* Position below orb when near top of screen */
        .transcript-tooltip.below {
            bottom: auto;
            top: 115px;
            transform: translateY(-10px);
        }
        
        .transcript-tooltip.below.visible {
            transform: translateY(0);
        }
        
        .transcript-tooltip.below.fading {
            transform: translateY(10px);
        }
        
        /* Align to left side of window when orb is near right edge of screen */
        .transcript-tooltip.align-left {
            right: auto;
            left: 0;
        }
        
        /* Align to right side (default) when orb is near left edge of screen */
        .transcript-tooltip.align-right {
            left: auto;
            right: 0;
        }
        
        /* ==================== CONTEXT MENU ==================== */
        .orb-context-menu {
            position: fixed;
            top: 50px;
            left: 50px;
            background: linear-gradient(135deg, rgba(20, 20, 30, 0.98) 0%, rgba(30, 30, 45, 0.95) 100%);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            padding: 6px;
            min-width: 160px;
            box-shadow: 
                0 12px 40px rgba(0, 0, 0, 0.5),
                0 0 0 1px rgba(255, 255, 255, 0.05),
                inset 0 1px 0 rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            opacity: 0;
            transform: scale(0.95) translateY(-5px);
            transform-origin: top left;
            transition: opacity 0.15s ease, transform 0.15s ease;
            pointer-events: none;
            z-index: 1000;
            -webkit-app-region: no-drag;
        }
        
        .orb-context-menu.visible {
            opacity: 1;
            transform: scale(1) translateY(0);
            pointer-events: auto;
        }
        
        .context-menu-item {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 10px 14px;
            color: rgba(255, 255, 255, 0.9);
            font-size: 13px;
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Text', sans-serif;
            border-radius: 8px;
            cursor: pointer;
            transition: background 0.15s ease;
            -webkit-app-region: no-drag;
        }
        
        .context-menu-item:hover {
            background: rgba(255, 255, 255, 0.1);
        }
        
        .context-menu-item svg {
            width: 16px;
            height: 16px;
            fill: currentColor;
            opacity: 0.8;
        }
        
        .context-menu-divider {
            height: 1px;
            background: rgba(255, 255, 255, 0.1);
            margin: 6px 8px;
        }
        
        /* ==================== TEXT CHAT PANEL ==================== */
        .text-chat-panel {
            position: fixed;
            top: 15px;
            left: 15px;
            right: 15px;
            bottom: 120px;
            background: linear-gradient(135deg, rgba(15, 15, 25, 0.98) 0%, rgba(25, 25, 40, 0.95) 100%);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 16px;
            box-shadow: 
                0 20px 60px rgba(0, 0, 0, 0.5),
                0 0 0 1px rgba(255, 255, 255, 0.05),
                inset 0 1px 0 rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(30px);
            -webkit-backdrop-filter: blur(30px);
            display: flex;
            flex-direction: column;
            opacity: 0;
            transform: scale(0.95) translateY(10px);
            transform-origin: bottom center;
            transition: opacity 0.25s ease, transform 0.25s cubic-bezier(0.4, 0, 0.2, 1);
            pointer-events: none;
            z-index: 500;
            -webkit-app-region: no-drag;
            overflow: hidden;
        }
        
        .text-chat-panel.visible {
            opacity: 1;
            transform: scale(1) translateY(0);
            pointer-events: auto;
        }
        
        .chat-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 16px 20px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        .chat-header-title {
            display: flex;
            align-items: center;
            gap: 10px;
            color: rgba(255, 255, 255, 0.95);
            font-size: 14px;
            font-weight: 500;
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Text', sans-serif;
        }
        
        .chat-header-title svg {
            width: 18px;
            height: 18px;
            fill: currentColor;
            opacity: 0.8;
        }
        
        .chat-close-btn {
            width: 28px;
            height: 28px;
            border-radius: 8px;
            border: none;
            background: rgba(255, 255, 255, 0.05);
            color: rgba(255, 255, 255, 0.6);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.15s ease;
        }
        
        .chat-close-btn:hover {
            background: rgba(255, 255, 255, 0.1);
            color: rgba(255, 255, 255, 0.9);
        }
        
        .chat-close-btn svg {
            width: 14px;
            height: 14px;
            fill: currentColor;
        }
        
        .chat-messages {
            flex: 1;
            overflow-y: auto;
            padding: 16px;
            display: flex;
            flex-direction: column;
            gap: 12px;
            min-height: 100px;
        }
        
        .chat-messages::-webkit-scrollbar {
            width: 6px;
        }
        
        .chat-messages::-webkit-scrollbar-track {
            background: transparent;
        }
        
        .chat-messages::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.15);
            border-radius: 3px;
        }
        
        .chat-message {
            padding: 12px 16px;
            border-radius: 16px;
            font-size: 13px;
            line-height: 1.5;
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Text', sans-serif;
            max-width: 85%;
            animation: message-appear 0.2s ease;
        }
        
        @keyframes message-appear {
            from {
                opacity: 0;
                transform: translateY(8px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        .chat-message.user {
            align-self: flex-end;
            background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
            color: white;
            border-bottom-right-radius: 6px;
        }
        
        .chat-message.assistant {
            align-self: flex-start;
            background: rgba(255, 255, 255, 0.08);
            color: rgba(255, 255, 255, 0.9);
            border-bottom-left-radius: 6px;
        }
        
        .chat-message.system {
            align-self: center;
            background: transparent;
            color: rgba(255, 255, 255, 0.5);
            font-size: 12px;
            padding: 8px;
        }
        
        .chat-input-container {
            padding: 16px;
            border-top: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        .chat-input-wrapper {
            display: flex;
            align-items: center;
            gap: 10px;
            background: rgba(255, 255, 255, 0.06);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 14px;
            padding: 4px 4px 4px 16px;
            transition: all 0.15s ease;
        }
        
        .chat-input-wrapper:focus-within {
            border-color: rgba(139, 92, 246, 0.5);
            box-shadow: 0 0 0 3px rgba(139, 92, 246, 0.15);
        }
        
        .chat-input {
            flex: 1;
            background: transparent;
            border: none;
            outline: none;
            color: rgba(255, 255, 255, 0.95);
            font-size: 14px;
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Text', sans-serif;
            padding: 10px 0;
        }
        
        .chat-input::placeholder {
            color: rgba(255, 255, 255, 0.35);
        }
        
        .chat-send-btn {
            width: 36px;
            height: 36px;
            border-radius: 10px;
            border: none;
            background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
            color: white;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.15s ease;
            flex-shrink: 0;
        }
        
        .chat-send-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 12px rgba(139, 92, 246, 0.4);
        }
        
        .chat-send-btn:active {
            transform: scale(0.95);
        }
        
        .chat-send-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
        
        .chat-send-btn svg {
            width: 16px;
            height: 16px;
            fill: currentColor;
        }
        
        /* Empty state */
        .chat-empty {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100%;
            padding: 40px 20px;
            color: rgba(255, 255, 255, 0.4);
            text-align: center;
        }
        
        .chat-empty svg {
            width: 48px;
            height: 48px;
            fill: currentColor;
            margin-bottom: 16px;
            opacity: 0.5;
        }
        
        .chat-empty-text {
            font-size: 13px;
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <!-- Context Menu - outside container for proper positioning -->
    <div class="orb-context-menu" id="contextMenu">
        <div class="context-menu-item" id="menuTextChat">
            <svg viewBox="0 0 24 24"><path d="M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z"/></svg>
            <span>Text Chat</span>
        </div>
        <div class="context-menu-item" id="menuVoice">
            <svg viewBox="0 0 24 24"><path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm-1-9c0-.55.45-1 1-1s1 .45 1 1v6c0 .55-.45 1-1 1s-1-.45-1-1V5zm6 6c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/></svg>
            <span>Voice Mode</span>
        </div>
        <div class="context-menu-divider"></div>
        <div class="context-menu-item" id="menuSettings">
            <svg viewBox="0 0 24 24"><path d="M19.14 12.94c.04-.31.06-.63.06-.94 0-.31-.02-.63-.06-.94l2.03-1.58c.18-.14.23-.41.12-.61l-1.92-3.32c-.12-.22-.37-.29-.59-.22l-2.39.96c-.5-.38-1.03-.7-1.62-.94l-.36-2.54c-.04-.24-.24-.41-.48-.41h-3.84c-.24 0-.43.17-.47.41l-.36 2.54c-.59.24-1.13.57-1.62.94l-2.39-.96c-.22-.08-.47 0-.59.22L2.74 8.87c-.12.21-.08.47.12.61l2.03 1.58c-.04.31-.06.63-.06.94s.02.63.06.94l-2.03 1.58c-.18.14-.23.41-.12.61l1.92 3.32c.12.22.37.29.59.22l2.39-.96c.5.38 1.03.7 1.62.94l.36 2.54c.05.24.24.41.48.41h3.84c.24 0 .44-.17.47-.41l.36-2.54c.59-.24 1.13-.56 1.62-.94l2.39.96c.22.08.47 0 .59-.22l1.92-3.32c.12-.22.07-.47-.12-.61l-2.01-1.58zM12 15.6c-1.98 0-3.6-1.62-3.6-3.6s1.62-3.6 3.6-3.6 3.6 1.62 3.6 3.6-1.62 3.6-3.6 3.6z"/></svg>
            <span>Settings</span>
        </div>
    </div>
    
    <!-- Text Chat Panel - outside container for proper positioning -->

    <div class="orb-container">
        <div class="orb" id="orb" title="Click to start listening">
            <div class="mic-overlay">
                <svg viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm-1-9c0-.55.45-1 1-1s1 .45 1 1v6c0 .55-.45 1-1 1s-1-.45-1-1V5zm6 6c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                </svg>
            </div>
        </div>
        <div class="ring"></div>
        <div class="ring-secondary"></div>
        <div class="transcript-tooltip" id="transcript"></div>
    </div>
        
    <!-- Text Chat Panel -->
        <div class="text-chat-panel" id="textChatPanel">
            <div class="chat-header">
                <div class="chat-header-title">
                    <svg viewBox="0 0 24 24"><path d="M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z"/></svg>
                    <span>Chat</span>
                </div>
                <button class="chat-close-btn" id="chatCloseBtn">
                    <svg viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
                </button>
            </div>
            <div class="chat-messages" id="chatMessages">
                <div class="chat-empty">
                    <svg viewBox="0 0 24 24"><path d="M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z"/></svg>
                    <div class="chat-empty-text">
                        Type a command or ask a question.<br/>
                        Same as voice, just quieter.
                    </div>
                </div>
            </div>
            <div class="chat-input-container">
                <div class="chat-input-wrapper">
                    <input type="text" class="chat-input" id="chatInput" placeholder="Type a message..." autocomplete="off" />
                    <button class="chat-send-btn" id="chatSendBtn">
                        <svg viewBox="0 0 24 24"><path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/></svg>
                    </button>
                </div>
            </div>
        </div>
    
    <script>
        // State
        let isListening = false;
        let isConnected = false;
        let isSessionReady = false;
        let pendingSpeak = null; // Text to speak when session is ready
        let removeEventListener = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let ttsAudio = null;
        
        // Audio playback for OpenAI Realtime TTS
        let ttsAudioContext = null;
        let ttsAudioChunks = [];
        let isSpeaking = false;
        
        // Deduplication and feedback loop prevention
        let lastProcessedTranscript = '';
        let lastProcessedTime = 0;
        const DEDUP_WINDOW_MS = 2000; // Ignore same transcript within 2 seconds
        let ttsEndTime = 0;
        const TTS_COOLDOWN_MS = 1500; // Ignore transcripts for 1.5s after TTS ends
        let pendingSpeakQueue = []; // Queue TTS requests to avoid collision
        
        // Initialize audio context for TTS playback
        function initTTSAudio() {
            if (!ttsAudioContext) {
                ttsAudioContext = new AudioContext({ sampleRate: 24000 });
            }
            return ttsAudioContext;
        }
        
        // Convert base64 PCM16 to Float32 for playback
        function base64ToFloat32(base64) {
            const binaryString = atob(base64);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            const pcm16 = new Int16Array(bytes.buffer);
            const float32 = new Float32Array(pcm16.length);
            for (let i = 0; i < pcm16.length; i++) {
                float32[i] = pcm16[i] / 32768;
            }
            return float32;
        }
        
        // Play accumulated audio chunks
        async function playTTSAudio() {
            if (ttsAudioChunks.length === 0) return;
            
            const ctx = initTTSAudio();
            if (ctx.state === 'suspended') {
                await ctx.resume();
            }
            
            // Combine all chunks
            const totalLength = ttsAudioChunks.reduce((sum, chunk) => sum + chunk.length, 0);
            const combined = new Float32Array(totalLength);
            let offset = 0;
            for (const chunk of ttsAudioChunks) {
                combined.set(chunk, offset);
                offset += chunk.length;
            }
            
            // Create buffer and play
            const buffer = ctx.createBuffer(1, combined.length, 24000);
            buffer.copyToChannel(combined, 0);
            
            const source = ctx.createBufferSource();
            source.buffer = buffer;
            source.connect(ctx.destination);
            source.start();
            
            console.log('[Orb] Playing TTS audio, samples:', combined.length);
            ttsAudioChunks = [];
        }
        
        // Play TTS audio feedback using OpenAI Realtime
        // Queued to prevent "active response in progress" errors
        async function speakFeedback(text) {
            // Add to queue
            pendingSpeakQueue.push(text);
            
            // If already speaking, the queue will be processed when current TTS finishes
            if (isSpeaking) {
                console.log('[Orb] TTS queued:', text);
                return;
            }
            
            // Process the queue
            await processSpeakQueue();
        }
        
        async function processSpeakQueue() {
            if (isSpeaking || pendingSpeakQueue.length === 0) return;
            
            const text = pendingSpeakQueue.shift();
            
            try {
                isSpeaking = true;
                ttsAudioChunks = [];
                
                // Use OpenAI Realtime to speak
                const result = await window.orbAPI.speak(text);
                
                if (!result.success) {
                    console.error('[Orb] TTS failed:', result.error);
                    isSpeaking = false;
                    ttsEndTime = Date.now();
                    // Try next in queue
                    setTimeout(() => processSpeakQueue(), 100);
                }
                // Audio will come via events (audio_delta, audio_done)
            } catch (error) {
                console.error('[Orb] TTS error:', error);
                isSpeaking = false;
                ttsEndTime = Date.now();
                // Try next in queue
                setTimeout(() => processSpeakQueue(), 100);
            }
        }
        
        // ==================== DISAMBIGUATION STATE ====================
        let pendingDisambiguation = null;
        let disambiguationListenerRemove = null;
        
        /**
         * Handle disambiguation flow
         * @param {Object} result - Classification result with clarification data
         * @param {string} originalTranscript - The original user transcript
         */
        async function handleDisambiguation(result, originalTranscript) {
            console.log('[Orb] Starting disambiguation flow:', result);
            
            // Create disambiguation state
            const disambiguationState = {
                id: 'disamb_' + Date.now(),
                originalTranscript: originalTranscript,
                question: result.clarificationQuestion || 'What did you mean?',
                options: result.clarificationOptions || [],
                createdAt: Date.now(),
                expiresAt: Date.now() + 30000, // 30 second timeout
            };
            
            pendingDisambiguation = disambiguationState;
            
            // Speak the clarifying question
            speakFeedback(disambiguationState.question);
            
            // Show disambiguation in HUD
            if (window.orbAPI.showDisambiguation) {
                try {
                    await window.orbAPI.showDisambiguation(disambiguationState);
                } catch (e) {
                    console.warn('[Orb] Could not show disambiguation HUD:', e);
                }
            }
            
            // Show transcript with question
            showTranscript(disambiguationState.question, false);
            
            // Set up listener for disambiguation response
            setupDisambiguationListeners();
        }
        
        /**
         * Set up listeners for disambiguation responses
         */
        function setupDisambiguationListeners() {
            // Clean up previous listener if any
            if (disambiguationListenerRemove) {
                disambiguationListenerRemove();
                disambiguationListenerRemove = null;
            }
            
            // Listen for option selection from HUD
            if (window.orbAPI.onDisambiguationSelected) {
                disambiguationListenerRemove = window.orbAPI.onDisambiguationSelected((selection) => {
                    console.log('[Orb] Disambiguation option selected:', selection);
                    resolveDisambiguation(selection);
                });
            }
            
            // Set timeout to cancel disambiguation
            setTimeout(() => {
                if (pendingDisambiguation) {
                    console.log('[Orb] Disambiguation timed out');
                    cancelDisambiguation();
                    speakFeedback('No response received');
                }
            }, 30000);
        }
        
        /**
         * Resolve disambiguation with selected option
         * @param {Object} selection - { optionIndex, option, mergedTranscript }
         */
        async function resolveDisambiguation(selection) {
            if (!pendingDisambiguation) return;
            
            console.log('[Orb] Resolving disambiguation:', selection);
            
            const state = pendingDisambiguation;
            pendingDisambiguation = null;
            
            // Clean up listeners
            if (disambiguationListenerRemove) {
                disambiguationListenerRemove();
                disambiguationListenerRemove = null;
            }
            
            // Hide transcript
            hideTranscript();
            
            // If we got a selected option with action, submit it directly
            if (selection.option && selection.option.action) {
                speakFeedback('Got it');
                
                // Submit the selected action directly
                try {
                    const result = await window.orbAPI.submitAction({
                        action: selection.option.action,
                        params: selection.option.params || {},
                        originalTranscript: state.originalTranscript,
                        clarification: selection.option.label,
                    });
                    
                    console.log('[Orb] Disambiguation action submitted:', result);
                    
                    if (result.queued) {
                        speakFeedback('One moment');
                    }
                } catch (err) {
                    console.error('[Orb] Error submitting disambiguation action:', err);
                    speakFeedback('Sorry, something went wrong');
                }
            } else if (selection.mergedTranscript) {
                // Re-classify with merged transcript
                speakFeedback('Let me try again');
                await processVoiceCommand(selection.mergedTranscript);
            }
        }
        
        /**
         * Cancel pending disambiguation
         */
        function cancelDisambiguation() {
            if (!pendingDisambiguation) return;
            
            console.log('[Orb] Cancelling disambiguation');
            
            pendingDisambiguation = null;
            
            if (disambiguationListenerRemove) {
                disambiguationListenerRemove();
                disambiguationListenerRemove = null;
            }
            
            hideTranscript();
            
            if (window.orbAPI.cancelDisambiguation) {
                window.orbAPI.cancelDisambiguation();
            }
        }
        
        /**
         * Check if we're waiting for disambiguation
         */
        function isAwaitingDisambiguation() {
            return pendingDisambiguation !== null && 
                   pendingDisambiguation.expiresAt > Date.now();
        }
        
        // ==================== VOICE COMMAND PROCESSING ====================
        
        // Process voice command - classify and queue via SDK
        async function processVoiceCommand(transcript) {
            console.log('[Orb] Processing command:', transcript);
            
            // Check if Agent Composer is active - relay voice to it
            if (window.orbAPI?.isComposerActive) {
                try {
                    const composerActive = await window.orbAPI.isComposerActive();
                    if (composerActive) {
                        console.log('[Orb] Relaying to Agent Composer:', transcript);
                        
                        // Cancel any AI response since we're handling locally
                        if (window.orbAPI.cancelResponse) {
                            await window.orbAPI.cancelResponse();
                        }
                        
                        const relayed = await window.orbAPI.relayToComposer(transcript);
                        if (relayed) {
                            // Don't process further - Composer will handle it
                            return;
                        }
                    }
                } catch (e) {
                    console.warn('[Orb] Could not check composer status:', e);
                }
            }
            
            // Check if this is a response to a pending disambiguation
            if (isAwaitingDisambiguation()) {
                console.log('[Orb] Processing as disambiguation response');
                
                // Try to match to an option
                const state = pendingDisambiguation;
                const normalizedResponse = transcript.toLowerCase().trim();
                
                // Try number matching
                const numberWords = {
                    'one': 0, 'first': 0, '1': 0,
                    'two': 1, 'second': 1, '2': 1,
                    'three': 2, 'third': 2, '3': 2,
                    'four': 3, 'fourth': 3, '4': 3,
                    'five': 4, 'fifth': 4, '5': 4,
                };
                
                let matchedIndex = -1;
                for (const [word, index] of Object.entries(numberWords)) {
                    if (normalizedResponse.includes(word) && index < state.options.length) {
                        matchedIndex = index;
                        break;
                    }
                }
                
                // Try label matching if number didn't work
                if (matchedIndex === -1) {
                    matchedIndex = state.options.findIndex(opt =>
                        normalizedResponse.includes(opt.label.toLowerCase()) ||
                        opt.label.toLowerCase().includes(normalizedResponse)
                    );
                }
                
                if (matchedIndex >= 0) {
                    resolveDisambiguation({
                        optionIndex: matchedIndex,
                        option: state.options[matchedIndex],
                        mergedTranscript: `${state.originalTranscript} (clarification: ${state.options[matchedIndex].label})`,
                    });
                } else {
                    // Use the voice response as additional context
                    resolveDisambiguation({
                        mergedTranscript: `${state.originalTranscript} (user clarified: ${transcript})`,
                    });
                }
                return;
            }
            
            try {
                // Submit to SDK for classification and queueing
                // The SDK will:
                // 1. Classify the transcript
                // 2. Create a task
                // 3. Queue it for execution
                // 4. Dispatch to an agent
                // 5. Broadcast events (which update HUD automatically)
                const result = await window.orbAPI.submit(transcript);
                console.log('[Orb] SDK submit result:', result);
                
                // Check if disambiguation is needed
                if (result.clarificationNeeded && result.clarificationOptions?.length > 0) {
                    await handleDisambiguation(result, transcript);
                    return;
                }
                
                if (result.queued && result.task) {
                    // Task was successfully queued
                    // Voice feedback - confirm and acknowledge
                    speakFeedback('One moment');
                    
                    console.log('[Orb] Task queued:', result.task.id, 'action:', result.action);
                    
                } else if (result.classified && result.action) {
                    // Classified but not queued (SDK not fully running?)
                    // Fall back to showing result in HUD manually
                    const task = {
                        id: 'task_' + Date.now(),
                        transcript: transcript,
                        action: result.action,
                        params: result.params || {},
                        confidence: result.confidence,
                        status: 'running',
                        timestamp: Date.now()
                    };
                    
                    try {
                        await window.orbAPI.showHUD(task);
                    } catch (e) {
                        console.warn('[Orb] Could not show HUD:', e);
                    }
                    
                    speakFeedback('Working on it');
                    
                    // Simulate completion
                    setTimeout(async () => {
                        try {
                            await window.orbAPI.sendHUDResult({
                                success: true,
                                message: `Action "${result.action}" completed`,
                            });
                        } catch (e) {
                            console.warn('[Orb] Could not send HUD result:', e);
                        }
                        speakFeedback('Done');
                    }, 1000);
                    
                } else {
                    // No action recognized
                    const task = {
                        id: 'task_' + Date.now(),
                        transcript: transcript,
                        action: 'Unknown',
                        status: 'completed',
                        timestamp: Date.now()
                    };
                    
                    try {
                        await window.orbAPI.showHUD(task);
                        await window.orbAPI.sendHUDResult({
                            success: true,
                            message: 'No specific action recognized. Transcript recorded.',
                        });
                    } catch (e) {
                        console.warn('[Orb] Could not update HUD:', e);
                    }
                    
                    speakFeedback('Got it');
                }
                
            } catch (err) {
                console.error('[Orb] Submit error:', err);
                
                // Show error in HUD
                try {
                    await window.orbAPI.sendHUDResult({
                        success: false,
                        error: err.message || 'Processing failed',
                    });
                } catch (e) {
                    console.warn('[Orb] Could not send HUD error:', e);
                }
                
                speakFeedback('Sorry, something went wrong');
            }
        }
        
        // Listen for retry requests from HUD
        if (window.orbAPI.onHUDRetry) {
            window.orbAPI.onHUDRetry((task) => {
                console.log('[Orb] Retry requested for:', task.transcript);
                if (task.transcript) {
                    processVoiceCommand(task.transcript);
                }
            });
        }
        
        // DOM elements
        const orb = document.getElementById('orb');
        const transcriptEl = document.getElementById('transcript');
        const contextMenu = document.getElementById('contextMenu');
        const textChatPanel = document.getElementById('textChatPanel');
        const chatMessages = document.getElementById('chatMessages');
        
        // Debug: check if elements exist
        console.log('[Orb] Elements found:', {
            orb: !!orb,
            contextMenu: !!contextMenu,
            textChatPanel: !!textChatPanel
        });
        const chatInput = document.getElementById('chatInput');
        const chatSendBtn = document.getElementById('chatSendBtn');
        const chatCloseBtn = document.getElementById('chatCloseBtn');
        
        // Text chat state
        let isTextChatOpen = false;
        let chatHistory = [];
        
        // ==================== CONTEXT MENU ====================
        
        function showContextMenu(x, y) {
            console.log('[Orb] Showing context menu at', x, y);
            
            // Position menu at click location, but ensure it's visible
            const menuWidth = 180;
            const menuHeight = 150;
            const windowWidth = window.innerWidth;
            const windowHeight = window.innerHeight;
            
            // Adjust if menu would go off-screen
            let menuX = x;
            let menuY = y;
            
            if (x + menuWidth > windowWidth) {
                menuX = windowWidth - menuWidth - 10;
            }
            if (y + menuHeight > windowHeight) {
                menuY = y - menuHeight;
            }
            
            contextMenu.style.position = 'fixed';
            contextMenu.style.left = menuX + 'px';
            contextMenu.style.top = menuY + 'px';
            contextMenu.style.bottom = 'auto';
            contextMenu.style.right = 'auto';
            
            contextMenu.classList.add('visible');
            console.log('[Orb] Context menu should be visible now');
        }
        
        function hideContextMenu() {
            contextMenu.classList.remove('visible');
        }
        
        // Context menu handlers
        document.getElementById('menuTextChat').addEventListener('click', () => {
            hideContextMenu();
            openTextChat();
        });
        
        document.getElementById('menuVoice').addEventListener('click', () => {
            hideContextMenu();
            closeTextChat();
            if (!isListening) {
                startListening();
            }
        });
        
        document.getElementById('menuSettings').addEventListener('click', () => {
            hideContextMenu();
            // Open settings via IPC
            if (window.orbAPI?.openSettings) {
                window.orbAPI.openSettings();
            }
        });
        
        // Close menu on click outside
        document.addEventListener('click', (e) => {
            if (!contextMenu.contains(e.target) && e.target !== orb) {
                hideContextMenu();
            }
        });
        
        // ==================== TEXT CHAT ====================
        
        function openTextChat() {
            isTextChatOpen = true;
            textChatPanel.classList.add('visible');
            setTimeout(() => chatInput.focus(), 150);
        }
        
        function closeTextChat() {
            isTextChatOpen = false;
            textChatPanel.classList.remove('visible');
        }
        
        chatCloseBtn.addEventListener('click', closeTextChat);
        
        function addChatMessage(type, text) {
            // Remove empty state if present
            const emptyState = chatMessages.querySelector('.chat-empty');
            if (emptyState) {
                emptyState.remove();
            }
            
            const msg = document.createElement('div');
            msg.className = `chat-message ${type}`;
            msg.textContent = text;
            chatMessages.appendChild(msg);
            chatMessages.scrollTop = chatMessages.scrollHeight;
            
            chatHistory.push({ type, text, timestamp: Date.now() });
        }
        
        async function sendChatMessage() {
            const text = chatInput.value.trim();
            if (!text) return;
            
            // Clear input
            chatInput.value = '';
            chatSendBtn.disabled = true;
            
            // Add user message
            addChatMessage('user', text);
            
            // Process through the same command handler as voice
            try {
                // Show processing state
                addChatMessage('system', 'Processing...');
                
                // Use the same processVoiceCommand function
                await processVoiceCommand(text);
                
                // Remove processing message
                const processingMsg = chatMessages.querySelector('.chat-message.system:last-child');
                if (processingMsg && processingMsg.textContent === 'Processing...') {
                    processingMsg.remove();
                }
                
                // Add confirmation
                addChatMessage('assistant', 'Got it. Working on that.');
                
            } catch (error) {
                console.error('[TextChat] Error:', error);
                addChatMessage('assistant', 'Sorry, something went wrong.');
            }
            
            chatSendBtn.disabled = false;
        }
        
        chatSendBtn.addEventListener('click', sendChatMessage);
        
        chatInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                sendChatMessage();
            }
            if (e.key === 'Escape') {
                closeTextChat();
            }
        });
        
        // Update UI based on state
        function updateUI(state, text = '') {
            orb.classList.remove('listening', 'processing', 'error');
            
            switch (state) {
                case 'listening':
                    orb.classList.add('listening');
                    orb.title = 'Click to stop';
                    break;
                case 'processing':
                    orb.classList.add('processing');
                    break;
                case 'error':
                    orb.classList.add('error');
                    showTranscript(text || 'Error occurred', false);
                    setTimeout(() => {
                        orb.classList.remove('error');
                        hideTranscript();
                    }, 3000);
                    break;
                default:
                    orb.title = 'Click to start listening';
            }
        }
        
        let hideTranscriptTimeout = null;
        
        function showTranscript(text, isInterim = false) {
            // Clear any pending hide
            if (hideTranscriptTimeout) {
                clearTimeout(hideTranscriptTimeout);
                hideTranscriptTimeout = null;
            }
            
            // Remove fading state if it was fading
            transcriptEl.classList.remove('fading');
            
            transcriptEl.textContent = text;
            transcriptEl.classList.add('visible');
            transcriptEl.classList.toggle('interim', isInterim);
            
            // Smart positioning based on screen position
            const windowX = window.screenX;
            const windowY = window.screenY;
            const screenWidth = window.screen.availWidth;
            
            // Vertical: show below if near top of screen
            if (windowY < 120) {
                transcriptEl.classList.add('below');
            } else {
                transcriptEl.classList.remove('below');
            }
            
            // Horizontal: align based on screen edge
            transcriptEl.classList.remove('align-left', 'align-right');
            if (windowX < 150) {
                // Near left edge - align tooltip to the right
                transcriptEl.classList.add('align-right');
            } else if (windowX > screenWidth - 350) {
                // Near right edge - align tooltip to the left
                transcriptEl.classList.add('align-left');
            }
            // Otherwise stays centered (default)
        }
        
        function hideTranscript() {
            // Start elegant fade out
            transcriptEl.classList.add('fading');
            transcriptEl.classList.remove('visible');
            
            // Clean up classes after animation completes
            hideTranscriptTimeout = setTimeout(() => {
                transcriptEl.classList.remove('fading', 'below', 'align-left', 'align-right', 'interim');
            }, 800);
        }
        
        // Convert Float32Array to base64 PCM16
        function floatTo16BitPCM(float32Array) {
            const buffer = new ArrayBuffer(float32Array.length * 2);
            const view = new DataView(buffer);
            for (let i = 0; i < float32Array.length; i++) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            return btoa(String.fromCharCode.apply(null, new Uint8Array(buffer)));
        }
        
        // Start listening
        async function startListening() {
            if (isListening) return;
            
            // Reset dedup state for new session
            lastProcessedTranscript = '';
            lastProcessedTime = 0;
            ttsEndTime = 0;
            pendingSpeakQueue = [];
            
            try {
                // Request mic permission
                await window.orbAPI.requestMicPermission();
                
                // Connect to realtime speech API
                const result = await window.orbAPI.connect();
                if (!result.success) {
                    throw new Error(result.error || 'Failed to connect');
                }
                isConnected = true;
                
                // Set up event listener for transcripts and audio
                removeEventListener = window.orbAPI.onEvent((event) => {
                    if (event.type === 'session_updated') {
                        // Session is ready - now we can speak
                        isSessionReady = true;
                        console.log('[Orb] Session ready');
                        if (pendingSpeak) {
                            console.log('[Orb] Speaking pending text:', pendingSpeak);
                            speakFeedback(pendingSpeak);
                            pendingSpeak = null;
                        }
                    } else if (event.type === 'transcript_delta') {
                        showTranscript(event.text, true);
                    } else if (event.type === 'transcript') {
                        const text = event.text?.trim();
                        const now = Date.now();
                        
                        // Skip if empty or too short
                        if (!text || text.length <= 3) {
                            console.log('[Orb] Ignoring short transcript:', text);
                            return;
                        }
                        
                        // Skip if within TTS cooldown (prevents feedback loop)
                        if (now - ttsEndTime < TTS_COOLDOWN_MS) {
                            console.log('[Orb] Ignoring transcript during TTS cooldown:', text);
                            return;
                        }
                        
                        // Skip if duplicate within dedup window
                        const normalizedText = text.toLowerCase();
                        const normalizedLast = lastProcessedTranscript.toLowerCase();
                        if (normalizedText === normalizedLast && (now - lastProcessedTime) < DEDUP_WINDOW_MS) {
                            console.log('[Orb] Ignoring duplicate transcript:', text);
                            return;
                        }
                        
                        // Update dedup tracking
                        lastProcessedTranscript = text;
                        lastProcessedTime = now;
                        
                        showTranscript(text, false);
                        // Submit for classification and show HUD
                        processVoiceCommand(text);
                        // Hide transcript after a delay
                        setTimeout(hideTranscript, 3000);
                    } else if (event.type === 'audio_delta') {
                        // TTS audio chunk from OpenAI
                        if (isSpeaking && event.audio) {
                            const float32 = base64ToFloat32(event.audio);
                            ttsAudioChunks.push(float32);
                        }
                    } else if (event.type === 'audio_done') {
                        // TTS audio complete, play it
                        if (isSpeaking) {
                            playTTSAudio();
                            isSpeaking = false;
                            ttsEndTime = Date.now(); // Mark when TTS ended for cooldown
                            
                            // Process next item in speak queue
                            setTimeout(() => processSpeakQueue(), 200);
                            
                            // If listening was stopped while TTS was playing, now disconnect
                            if (!isListening && isConnected) {
                                console.log('[Orb] TTS complete, now disconnecting...');
                                finishAndDisconnect();
                                updateUI('idle');
                            }
                        }
                    } else if (event.type === 'error') {
                        updateUI('error', event.message || 'Speech error');
                        stopListening();
                    }
                });
                
                // Set up audio capture
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 24000,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                audioContext = new AudioContext({ sampleRate: 24000 });
                const source = audioContext.createMediaStreamSource(mediaStream);
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                processor.onaudioprocess = (e) => {
                    if (!isListening) return;
                    const inputData = e.inputBuffer.getChannelData(0);
                    const base64Audio = floatTo16BitPCM(inputData);
                    window.orbAPI.sendAudio(base64Audio);
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                isListening = true;
                updateUI('listening');
                console.log('[Orb] Started listening');
                
                // Say "ready" to indicate we're listening (wait for session to be ready)
                if (isSessionReady) {
                    speakFeedback('Ready');
                } else {
                    pendingSpeak = 'Ready';
                    console.log('[Orb] Session not ready yet, queueing speak');
                }
                
            } catch (error) {
                console.error('[Orb] Start error:', error);
                updateUI('error', error.message);
                stopListening();
            }
        }
        
        // Helper to finish cleanup and disconnect
        async function finishAndDisconnect() {
            // Clean up event listener
            if (removeEventListener) {
                removeEventListener();
                removeEventListener = null;
            }
            
            // Disconnect from API
            if (isConnected) {
                try {
                    await window.orbAPI.disconnect();
                } catch (e) {
                    console.error('[Orb] Disconnect error:', e);
                }
                isConnected = false;
            }
            
            isSessionReady = false;
        }
        
        // Stop listening
        async function stopListening() {
            if (!isListening && !isConnected) return;
            
            isListening = false;
            pendingSpeak = null;
            pendingSpeakQueue = []; // Clear any queued TTS
            
            // Clean up audio input (microphone)
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            // If TTS is in progress, delay disconnect until it's done
            if (isSpeaking) {
                console.log('[Orb] TTS in progress, delaying disconnect...');
                // Event listener stays active to receive audio_done
                // Disconnect will happen via finishAndDisconnect()
                return;
            }
            
            // Clean up event listener and disconnect
            finishAndDisconnect();
            
            updateUI('idle');
            console.log('[Orb] Stopped listening');
        }
        
        // ==========================================================================
        // DRAG SUPPORT
        // ==========================================================================
        
        let isDragging = false;
        let dragStartX = 0;
        let dragStartY = 0;
        let windowStartX = 0;
        let windowStartY = 0;
        let hasMoved = false;
        
        orb.addEventListener('mousedown', (e) => {
            // Only drag on left-click (button 0), not right-click (button 2)
            if (e.button !== 0) return;
            
            isDragging = true;
            hasMoved = false;
            dragStartX = e.screenX;
            dragStartY = e.screenY;
            // Capture window position at start of drag
            windowStartX = window.screenX;
            windowStartY = window.screenY;
            orb.style.cursor = 'grabbing';
            e.preventDefault();
        });
        
        document.addEventListener('mousemove', (e) => {
            if (!isDragging) return;
            
            // Calculate total delta from drag start
            const deltaX = e.screenX - dragStartX;
            const deltaY = e.screenY - dragStartY;
            
            // Only start moving if we've moved more than 5px (to distinguish from clicks)
            if (Math.abs(deltaX) > 5 || Math.abs(deltaY) > 5) {
                hasMoved = true;
                
                // Calculate new position based on initial window position + total delta
                const newX = windowStartX + deltaX;
                const newY = windowStartY + deltaY;
                
                window.orbAPI.setPosition(newX, newY);
            }
        });
        
        document.addEventListener('mouseup', () => {
            if (isDragging) {
                isDragging = false;
                orb.style.cursor = 'pointer';
            }
        });
        
        // Toggle listening on click (only if we didn't drag)
        orb.addEventListener('click', () => {
            if (hasMoved) {
                hasMoved = false;
                return;
            }
            
            // If text chat is open, close it and start voice
            if (isTextChatOpen) {
                closeTextChat();
            }
            
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        });
        
        // Right-click to show context menu
        orb.addEventListener('contextmenu', (e) => {
            console.log('[Orb] Right-click detected at', e.clientX, e.clientY);
            e.preventDefault();
            e.stopPropagation();
            showContextMenu(e.clientX, e.clientY);
        });
        
        // Also listen on document in case orb doesn't catch it
        document.addEventListener('contextmenu', (e) => {
            console.log('[Orb] Document right-click at', e.clientX, e.clientY);
            e.preventDefault();
            showContextMenu(e.clientX, e.clientY);
        });
        
        // Double-click as alternative to open text chat directly
        orb.addEventListener('dblclick', (e) => {
            console.log('[Orb] Double-click detected');
            e.preventDefault();
            openTextChat();
        });
        
        // Handle window close
        window.addEventListener('beforeunload', () => {
            stopListening();
        });
        
        // Listen for plan summary from Agent Composer
        if (window.orbAPI?.onPlanSummary) {
            window.orbAPI.onPlanSummary(async (data) => {
                console.log('[Orb] Received plan summary:', data.type);
                
                if (data.type === 'plan-ready' && data.summary) {
                    // Speak the plan summary via TTS
                    await speakFeedback(data.summary);
                } else if (data.type === 'creation-complete' && data.agentName) {
                    // Announce agent creation complete - conversational
                    await speakFeedback(`All set! ${data.agentName} is ready to use.`);
                }
            });
            console.log('[Orb] Agent Composer plan listener registered');
        }
        
        // Log ready state
        console.log('[Orb] Voice Orb initialized with drag support and Agent Composer integration');
    </script>
</body>
</html>
